open import ToddPrelude
open import RealNumbers
open import Searchers
open import Lossers
-- open import Regressors

open RealNumber {â„} ğ•£

Î³ : (X Y : Set) â†’ Set
Î³ X Y = Y â†’ (X â†’ Y) â†’ X

buildReg : {X Y : Set} (â„° : (X â†’ ğ”¹) â†’ X) â†’ (Î¦ : Y â†’ Y â†’ â„) â†’ â„ â†’ Î³ X Y
buildReg â„° Î¦ Îµ = Î» y m â†’ â„° (Î» x â†’ (Î¦ (m x) y <â„ Îµ))

RegressionConvergence : {X Y : Set} (L : LossSpace Y) (k : X) (f : X â†’ Y) â†’ Set
RegressionConvergence {X} {Y} L k f = âˆ€ Îµ â†’ (Îµâ‚€ : (â„â‚€ <â„ Îµ) â‰¡ tt)
                                                              â†’ âˆƒ (Î» (reg : Î³ X Y) â†’ ((LossSpace.Î¦ L) (f k) (f (reg (f k) f)) <â„ Îµ) â‰¡ tt)
                                                              
theorem : {X Y : Set} (S : Searchable X) (L : LossSpace Y) â†’ âˆ€ k f â†’ RegressionConvergence L k f
theorem {X} {Y} S L k f Îµ Îµâ‚€ = buildReg â„°â‚“ Î¦ Îµ â‡’ firstly thirdly where
  â„°â‚“ : (X â†’ ğ”¹) â†’ X
  â„°â‚“ = Searchable.Îµ S
  Î¦ : Y â†’ Y â†’ â„
  Î¦ = LossSpace.Î¦ L
  p : X â†’ ğ”¹
  p = Î» x â†’ Î¦ (f x) (f k) <â„ Îµ
  k' : X
  k' = â„°â‚“ p
  firstly : (p k' â‰¡ tt) â†’ (Î¦ (f k) (f k') <â„ Îµ) â‰¡ tt
  firstly r = transâ‰¡ (congâ‰¡ (Î» â–  â†’ â–  <â„ Îµ) (LossSpace.sym L (f k) (f k'))) r
  secondly : âˆƒ (Î» x â†’ p x â‰¡ tt)
  secondly = k â‡’ transâ‰¡ (congâ‰¡ (Î» â–  â†’ â–  <â„ Îµ) (LossSpace.ref L (f k))) Îµâ‚€
  thirdly : p k' â‰¡ tt
  thirdly = Searchable.def2 S p (Î â‚€ secondly) (Î â‚ secondly)

continuous : {Y Z : Set} (Î¦â‚ : Y â†’ Y â†’ â„) (Î¦â‚‚ : Z â†’ Z â†’ â„) (F : Y â†’ Z) â†’ Set
continuous {Y} {Z} Î¦â‚ Î¦â‚‚ F = âˆ€ Îµ â†’ (â„â‚€ <â„ Îµ) â‰¡ tt
                                                â†’ âˆƒ (Î» Î´ â†’ (((â„â‚€ <â„ Î´) â‰¡ tt) âˆ§ (âˆ€ (yâ‚ yâ‚‚ : Y) â†’ ((Î¦â‚ yâ‚ yâ‚‚ <â„ Î´) â‰¡ tt â†’ (Î¦â‚‚ (F yâ‚) (F yâ‚‚) <â„ Îµ) â‰¡ tt))))

RegressionConvergenceNoise : {X Y : Set} (Î¦ : Y â†’ Y â†’ â„) (Ïˆ : Y â†’ Y) (k : X) (f : X â†’ Y) â†’ Set
RegressionConvergenceNoise {X} {Y} Î¦ Ïˆ k f = âˆ€ Îµ â†’ (Îµâ‚€ : (â„â‚€ <â„ Îµ) â‰¡ tt)
                                                                             â†’ âˆƒ (Î» (reg : Î³ X Y) â†’ (Î¦ (Ïˆ (f k)) (f (reg (f k) f)) <â„ (Îµ +â„ (Î¦ (Ïˆ (f k)) (f k)))) â‰¡ tt)

theorem-noise : {X Y : Set}  (S : Searchable X) (L : LossSpace Y)
                      â†’ âˆ€ k f â†’ âˆ€ (Ïˆ : Y â†’ Y) â†’ continuous {Y} {â„} (LossSpace.Î¦ L) Î¦â„ (Î» y â†’ (LossSpace.Î¦ L) (Ïˆ (f k)) y)
                      â†’ RegressionConvergenceNoise (LossSpace.Î¦ L) Ïˆ k f
theorem-noise {X} {Y} S L k f Ïˆ C Îµ Îµâ‚€ = reg â‡’ (Î¦â„rule noise-diff) where
  R : RegressionConvergence {X} {Y} L k f
  R = theorem S L k f
  â„°â‚“ : (X â†’ ğ”¹) â†’ X
  â„°â‚“ = Searchable.Îµ S
  Î¦ : Y â†’ Y â†’ â„
  Î¦ = LossSpace.Î¦ L
  Î´ : â„
  Î´ = Î â‚€ (C Îµ Îµâ‚€)
  Î´â‚€ : (â„â‚€ <â„ Î´) â‰¡ tt
  Î´â‚€ = âˆ§l (Î â‚ (C Îµ Îµâ‚€))
  reg : Î³ X Y
  reg = Î â‚€ (R Î´ Î´â‚€)
  oracle regÎ´ noisy : Y
  oracle = f k
  regÎ´ = f (reg oracle f)
  noisy = Ïˆ oracle
  RconvÎ´ : ((Î¦ oracle regÎ´) <â„ Î´) â‰¡ tt
  RconvÎ´ = Î â‚ (R Î´ Î´â‚€)
  noise-diff : (Î¦â„ (Î¦ noisy oracle) (Î¦ noisy regÎ´) <â„ Îµ) â‰¡ tt
  noise-diff = âˆ§r (Î â‚ (C Îµ Îµâ‚€)) oracle regÎ´ RconvÎ´
